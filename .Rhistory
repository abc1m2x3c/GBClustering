for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_F[index]=rep(mean(start_beta_F[index]),length(index))
}
MLE_alpha_O = start_alpha_O
MLE_beta_O=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_O[index]=rep(mean(start_beta_O[index]),length(index))
}
start.mle.est=list(MLE_alpha_M,MLE_beta_M,MLE_alpha_F,MLE_beta_F,MLE_alpha_O,MLE_beta_O)
cluster.data=list(y,Z1,Z2)
mle.est=MLE.nuisance.param.B(cluster.data,start.mle.est,start.loc.B,end.loc.B)
#calculate the MLE for Z1 and Z2
llk_Z1Z2=llk.Z1Z2.realdata(cluster.data,mle.est,start.loc.B,end.loc.B)
llk_Z1Z2
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
res_D=fit.D.realdata(cluster.data,initial,start.loc.B,end.loc.B,max.iter)
my_cluster=res_D[[1]]
accuracy=rep(0,factorial(K))
all_perm=permn(seq(1:K))
for (i in 1:factorial(K)){
accuracy[i]=mean(ifelse(abs(match(my_cluster,all_perm[[i]])-cluster_assign),0,1))
}
max(accuracy)
BIC_record[count_K]=-2*res_D[[4]]+log(I*J*3)*(J*2+3*B+4*K-1)
#data generation
rm(list=ls(all=TRUE))
source('functions.R')
library(combinat)
library(maxLik)
max.iter=500
L=20
J=5000
B=J/L
I=50
K=4
# gamma_O=matrix(c(0.3,0,0.2,
#                  0.15,0.,0,
#                  -0.01,-0.3,0,
#                  -0.16,-0.2,0.14),
gamma_O=matrix(c(2.36,0,0.2,
2.24,0,0,
2.12,-0.3,0,
2.0,-0.2,0.14),
nrow=K,
ncol=3,byrow=TRUE)
beta_O_B=abs(rnorm(B,10,0.5)) # rep(10,B)#
beta_M_B=abs(rnorm(B,5,0.5)) # rep(5,B)#
beta_F_B=abs(rnorm(B,7,0.5)) # rep(7,B)#
beta_M=rep(beta_M_B,each=L)
beta_F=rep(beta_F_B,each=L)
beta_O=rep(beta_O_B,each=L)
alpha_M=abs(rnorm(J,5,0.5))
alpha_F=abs(rnorm(J,7,0.5))
p_cluster=rep(1/K,K)
res=data.generate(I,J,L,B,K,gamma_O,p_cluster,alpha_M,alpha_F,beta_M,beta_F,beta_O,beta_M_B,beta_F_B,beta_O_B)
cluster_assign=res[[1]]
alpha_O=res[[2]]
Z1=res[[3]]
Z2=res[[4]]
y=res[[5]]
start.loc.B=seq(1,J,L)
end.loc.B=seq(L,J,L)
start.loc.B
###MLE
#MLE
B=length(start.loc.B)
#MOM
#step 1: calculate the MOM of each CpG, each CpG has a unique estimation of alpha and beta
start_alpha_M=rep(0,J)
start_beta_M=rep(0,J)
start_alpha_F=rep(0,J)
start_beta_F=rep(0,J)
start_alpha_O=rep(0,J)
start_beta_O=rep(0,J)
for (j in 1:J){
start_alpha_O[j]=mean(y[,j])*(mean(y[,j])*(1-mean(y[,j]))/var(y[,j])-1)
start_alpha_M[j]=mean(Z1[,j])*(mean(Z1[,j])*(1-mean(Z1[,j]))/var(Z1[,j])-1)
start_alpha_F[j]=mean(Z2[,j])*(mean(Z2[,j])*(1-mean(Z2[,j]))/var(Z2[,j])-1)
start_beta_O[j]=(1/mean(y[,j])-1)*start_alpha_O[j]
start_beta_M[j]=(1/mean(Z1[,j])-1)*start_alpha_M[j]
start_beta_F[j]=(1/mean(Z2[,j])-1)*start_alpha_F[j]
}
#step 2: for those CpG in the same block, average their beta's to be the initial value for generalized beta distribution
MLE_alpha_M = start_alpha_M
MLE_beta_M=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_M[index]=rep(mean(start_beta_M[index]),length(index))
}
MLE_alpha_F = start_alpha_F
MLE_beta_F=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_F[index]=rep(mean(start_beta_F[index]),length(index))
}
MLE_alpha_O = start_alpha_O
MLE_beta_O=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_O[index]=rep(mean(start_beta_O[index]),length(index))
}
start.mle.est=list(MLE_alpha_M,MLE_beta_M,MLE_alpha_F,MLE_beta_F,MLE_alpha_O,MLE_beta_O)
cluster.data=list(y,Z1,Z2)
mle.est=MLE.nuisance.param.B(cluster.data,start.mle.est,start.loc.B,end.loc.B)
#calculate the MLE for Z1 and Z2
llk_Z1Z2=llk.Z1Z2.realdata(cluster.data,mle.est,start.loc.B,end.loc.B)
llk_Z1Z2
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
res_D=fit.D.realdata(cluster.data,initial,start.loc.B,end.loc.B,max.iter)
my_cluster=res_D[[1]]
accuracy=rep(0,factorial(K))
all_perm=permn(seq(1:K))
for (i in 1:factorial(K)){
accuracy[i]=mean(ifelse(abs(match(my_cluster,all_perm[[i]])-cluster_assign),0,1))
}
max(accuracy)
BIC_record[count_K]=-2*res_D[[4]]+log(I*J*3)*(J*2+3*B+4*K-1)
#data generation
rm(list=ls(all=TRUE))
source('functions.R')
library(combinat)
library(maxLik)
max.iter=500
L=20
J=5000
B=J/L
I=50
K=4
gamma_O=matrix(c(0.3,0,0.2,
0.15,0.,0,
-0.01,-0.3,0,
-0.16,-0.2,0.14),
# gamma_O=matrix(c(2.36,0,0.2,
#                  2.24,0,0,
#                  2.12,-0.3,0,
#                  2.0,-0.2,0.14),
nrow=K,
ncol=3,byrow=TRUE)
beta_O_B=abs(rnorm(B,10,0.5)) # rep(10,B)#
beta_M_B=abs(rnorm(B,5,0.5)) # rep(5,B)#
beta_F_B=abs(rnorm(B,7,0.5)) # rep(7,B)#
beta_M=rep(beta_M_B,each=L)
beta_F=rep(beta_F_B,each=L)
beta_O=rep(beta_O_B,each=L)
alpha_M=abs(rnorm(J,5,0.5))
alpha_F=abs(rnorm(J,7,0.5))
p_cluster=rep(1/K,K)
res=data.generate(I,J,L,B,K,gamma_O,p_cluster,alpha_M,alpha_F,beta_M,beta_F,beta_O,beta_M_B,beta_F_B,beta_O_B)
cluster_assign=res[[1]]
alpha_O=res[[2]]
Z1=res[[3]]
Z2=res[[4]]
y=res[[5]]
cor(y[,1],y[,2])
cor(y[,1],y[,200])
cor(y[,1],y[,20])
cor(y[,1],y[,21])
cor(y[,1],y[,22])
start.loc.B=seq(1,J,L)
start.loc.B
start.loc.B=res$start.index
end.loc.B
end.loc.B=seq(L,J,L)
end.loc.B
###MLE
#MLE
B=length(start.loc.B)
#MOM
#step 1: calculate the MOM of each CpG, each CpG has a unique estimation of alpha and beta
start_alpha_M=rep(0,J)
start_beta_M=rep(0,J)
start_alpha_F=rep(0,J)
start_beta_F=rep(0,J)
start_alpha_O=rep(0,J)
start_beta_O=rep(0,J)
for (j in 1:J){
start_alpha_O[j]=mean(y[,j])*(mean(y[,j])*(1-mean(y[,j]))/var(y[,j])-1)
start_alpha_M[j]=mean(Z1[,j])*(mean(Z1[,j])*(1-mean(Z1[,j]))/var(Z1[,j])-1)
start_alpha_F[j]=mean(Z2[,j])*(mean(Z2[,j])*(1-mean(Z2[,j]))/var(Z2[,j])-1)
start_beta_O[j]=(1/mean(y[,j])-1)*start_alpha_O[j]
start_beta_M[j]=(1/mean(Z1[,j])-1)*start_alpha_M[j]
start_beta_F[j]=(1/mean(Z2[,j])-1)*start_alpha_F[j]
}
#step 2: for those CpG in the same block, average their beta's to be the initial value for generalized beta distribution
MLE_alpha_M = start_alpha_M
MLE_beta_M=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_M[index]=rep(mean(start_beta_M[index]),length(index))
}
start.loc.B
start.loc.B=seq(1,J,L)
end.loc.B=seq(L,J,L)
###MLE
#MLE
B=length(start.loc.B)
#MOM
#step 1: calculate the MOM of each CpG, each CpG has a unique estimation of alpha and beta
start_alpha_M=rep(0,J)
start_beta_M=rep(0,J)
start_alpha_F=rep(0,J)
start_beta_F=rep(0,J)
start_alpha_O=rep(0,J)
start_beta_O=rep(0,J)
for (j in 1:J){
start_alpha_O[j]=mean(y[,j])*(mean(y[,j])*(1-mean(y[,j]))/var(y[,j])-1)
start_alpha_M[j]=mean(Z1[,j])*(mean(Z1[,j])*(1-mean(Z1[,j]))/var(Z1[,j])-1)
start_alpha_F[j]=mean(Z2[,j])*(mean(Z2[,j])*(1-mean(Z2[,j]))/var(Z2[,j])-1)
start_beta_O[j]=(1/mean(y[,j])-1)*start_alpha_O[j]
start_beta_M[j]=(1/mean(Z1[,j])-1)*start_alpha_M[j]
start_beta_F[j]=(1/mean(Z2[,j])-1)*start_alpha_F[j]
}
#step 2: for those CpG in the same block, average their beta's to be the initial value for generalized beta distribution
MLE_alpha_M = start_alpha_M
MLE_beta_M=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_M[index]=rep(mean(start_beta_M[index]),length(index))
}
MLE_alpha_F = start_alpha_F
MLE_beta_F=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_F[index]=rep(mean(start_beta_F[index]),length(index))
}
MLE_alpha_O = start_alpha_O
MLE_beta_O=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_O[index]=rep(mean(start_beta_O[index]),length(index))
}
###########################################################################
# MLE for nuisance parameters
###########################################################################
# MLE for nuisance parameters
start_alpha_M=rep(0,J)
start_beta_M=rep(0,J)
start_alpha_F=rep(0,J)
start_beta_F=rep(0,J)
start_alpha_O=rep(0,J)
start_beta_O=rep(0,J)
for (j in 1:J){
start_alpha_O[j]=mean(y[,j])*(mean(y[,j])*(1-mean(y[,j]))/var(y[,j])-1)
start_alpha_M[j]=mean(Z1[,j])*(mean(Z1[,j])*(1-mean(Z1[,j]))/var(Z1[,j])-1)
start_alpha_F[j]=mean(Z2[,j])*(mean(Z2[,j])*(1-mean(Z2[,j]))/var(Z2[,j])-1)
start_beta_O[j]=(1/mean(y[,j])-1)*start_alpha_O[j]
start_beta_M[j]=(1/mean(Z1[,j])-1)*start_alpha_M[j]
start_beta_F[j]=(1/mean(Z2[,j])-1)*start_alpha_F[j]
}
MLE_alpha_M = start_alpha_M
MLE_beta_M  = rep(colMeans(matrix(start_beta_M,nrow=L,ncol=B)),each=L)
MLE_alpha_F = start_alpha_F
MLE_beta_F  = rep(colMeans(matrix(start_beta_F,nrow=L,ncol=B)),each=L)
MLE_alpha_O = start_alpha_O
MLE_beta_O  = rep(colMeans(matrix(start_beta_O,nrow=L,ncol=B)),each=L)
###########################################################################
# fit-Dependent version
###########################################################################
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
cluster.data=list(y,Z1,Z2)
mle.est=list(MLE_alpha_M,MLE_beta_M,MLE_alpha_F,MLE_beta_F,MLE_alpha_O,MLE_beta_O)
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
#calculate the MLE for Z1 and Z2
llk_Z1Z2=llk.Z1Z2.realdata(cluster.data,mle.est,start.loc.B,end.loc.B)
llk_Z1Z2
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
res_D=fit.D.realdata(cluster.data,initial,start.loc.B,end.loc.B,max.iter)
max.iter=100
res_D=fit.D.realdata(cluster.data,initial,start.loc.B,end.loc.B,max.iter)
my_cluster=res_D[[1]]
accuracy=rep(0,factorial(K))
all_perm=permn(seq(1:K))
for (i in 1:factorial(K)){
accuracy[i]=mean(ifelse(abs(match(my_cluster,all_perm[[i]])-cluster_assign),0,1))
}
max(accuracy)
start.mle.est=list(MLE_alpha_M,MLE_beta_M,MLE_alpha_F,MLE_beta_F,MLE_alpha_O,MLE_beta_O)
cluster.data=list(y,Z1,Z2)
mle.est=MLE.nuisance.param.B(cluster.data,start.mle.est,start.loc.B,end.loc.B)
mle.est[1]
mle.est[[1]]
mle.est[[2]]
#calculate the MLE for Z1 and Z2
llk_Z1Z2=llk.Z1Z2.realdata(cluster.data,mle.est,start.loc.B,end.loc.B)
llk_Z1Z2
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
res_D=fit.D.realdata(cluster.data,initial,start.loc.B,end.loc.B,max.iter)
###########################################################################
# MLE for nuisance parameters
###########################################################################
# MLE for nuisance parameters
start_alpha_M=rep(0,J)
start_beta_M=rep(0,J)
start_alpha_F=rep(0,J)
start_beta_F=rep(0,J)
start_alpha_O=rep(0,J)
start_beta_O=rep(0,J)
for (j in 1:J){
start_alpha_O[j]=mean(y[,j])*(mean(y[,j])*(1-mean(y[,j]))/var(y[,j])-1)
start_alpha_M[j]=mean(Z1[,j])*(mean(Z1[,j])*(1-mean(Z1[,j]))/var(Z1[,j])-1)
start_alpha_F[j]=mean(Z2[,j])*(mean(Z2[,j])*(1-mean(Z2[,j]))/var(Z2[,j])-1)
start_beta_O[j]=(1/mean(y[,j])-1)*start_alpha_O[j]
start_beta_M[j]=(1/mean(Z1[,j])-1)*start_alpha_M[j]
start_beta_F[j]=(1/mean(Z2[,j])-1)*start_alpha_F[j]
}
MLE_alpha_M = start_alpha_M
MLE_beta_M  = rep(colMeans(matrix(start_beta_M,nrow=L,ncol=B)),each=L)
MLE_alpha_F = start_alpha_F
MLE_beta_F  = rep(colMeans(matrix(start_beta_F,nrow=L,ncol=B)),each=L)
MLE_alpha_O = start_alpha_O
MLE_beta_O  = rep(colMeans(matrix(start_beta_O,nrow=L,ncol=B)),each=L)
###########################################################################
# fit-Dependent version
###########################################################################
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
cluster.data=list(y,Z1,Z2)
mle.est=list(MLE_alpha_M,MLE_beta_M,MLE_alpha_F,MLE_beta_F,MLE_alpha_O,MLE_beta_O)
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
mle.est[[1]]
mle.est[[2]]
range(mle.est)
#MOM
#step 1: calculate the MOM of each CpG, each CpG has a unique estimation of alpha and beta
start_alpha_M=rep(0,J)
start_beta_M=rep(0,J)
start_alpha_F=rep(0,J)
start_beta_F=rep(0,J)
start_alpha_O=rep(0,J)
start_beta_O=rep(0,J)
for (j in 1:J){
start_alpha_O[j]=mean(y[,j])*(mean(y[,j])*(1-mean(y[,j]))/var(y[,j])-1)
start_alpha_M[j]=mean(Z1[,j])*(mean(Z1[,j])*(1-mean(Z1[,j]))/var(Z1[,j])-1)
start_alpha_F[j]=mean(Z2[,j])*(mean(Z2[,j])*(1-mean(Z2[,j]))/var(Z2[,j])-1)
start_beta_O[j]=(1/mean(y[,j])-1)*start_alpha_O[j]
start_beta_M[j]=(1/mean(Z1[,j])-1)*start_alpha_M[j]
start_beta_F[j]=(1/mean(Z2[,j])-1)*start_alpha_F[j]
}
#step 2: for those CpG in the same block, average their beta's to be the initial value for generalized beta distribution
MLE_alpha_M = start_alpha_M
MLE_beta_M=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_M[index]=rep(mean(start_beta_M[index]),length(index))
}
MLE_alpha_F = start_alpha_F
MLE_beta_F=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_F[index]=rep(mean(start_beta_F[index]),length(index))
}
MLE_alpha_O = start_alpha_O
MLE_beta_O=rep(0,J)
for (b in 1:B){
index=start.loc.B[b]:end.loc.B[b]
MLE_beta_O[index]=rep(mean(start_beta_O[index]),length(index))
}
start.mle.est=list(MLE_alpha_M,MLE_beta_M,MLE_alpha_F,MLE_beta_F,MLE_alpha_O,MLE_beta_O)
cluster.data=list(y,Z1,Z2)
mle.est=MLE.nuisance.param.B(cluster.data,start.mle.est,start.loc.B,end.loc.B)
range(mle.est)
#calculate the MLE for Z1 and Z2
llk_Z1Z2=llk.Z1Z2.realdata(cluster.data,mle.est,start.loc.B,end.loc.B)
llk_Z1Z2
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
res_D=fit.D.realdata(cluster.data,initial,start.loc.B,end.loc.B,max.iter)
###########################################################################
# MLE for nuisance parameters
###########################################################################
# MLE for nuisance parameters
start_alpha_M=rep(0,J)
start_beta_M=rep(0,J)
start_alpha_F=rep(0,J)
start_beta_F=rep(0,J)
start_alpha_O=rep(0,J)
start_beta_O=rep(0,J)
for (j in 1:J){
start_alpha_O[j]=mean(y[,j])*(mean(y[,j])*(1-mean(y[,j]))/var(y[,j])-1)
start_alpha_M[j]=mean(Z1[,j])*(mean(Z1[,j])*(1-mean(Z1[,j]))/var(Z1[,j])-1)
start_alpha_F[j]=mean(Z2[,j])*(mean(Z2[,j])*(1-mean(Z2[,j]))/var(Z2[,j])-1)
start_beta_O[j]=(1/mean(y[,j])-1)*start_alpha_O[j]
start_beta_M[j]=(1/mean(Z1[,j])-1)*start_alpha_M[j]
start_beta_F[j]=(1/mean(Z2[,j])-1)*start_alpha_F[j]
}
MLE_alpha_M = start_alpha_M
MLE_beta_M  = rep(colMeans(matrix(start_beta_M,nrow=L,ncol=B)),each=L)
MLE_alpha_F = start_alpha_F
MLE_beta_F  = rep(colMeans(matrix(start_beta_F,nrow=L,ncol=B)),each=L)
MLE_alpha_O = start_alpha_O
MLE_beta_O  = rep(colMeans(matrix(start_beta_O,nrow=L,ncol=B)),each=L)
###########################################################################
# fit-Dependent version
###########################################################################
start_cluster_assign=matrix(sample(x=1:K,size=J,replace=TRUE,prob=rep(1/K,K))) #starting point
start_gamma_O=matrix(rnorm(3*K),nrow=K,ncol=3)#gamma_O #
cluster.data=list(y,Z1,Z2)
mle.est=list(MLE_alpha_M,MLE_beta_M,MLE_alpha_F,MLE_beta_F,MLE_alpha_O,MLE_beta_O)
initial=list(start_gamma_O,rep(1/K,K),start_cluster_assign)
res_D=fit.D.realdata(cluster.data,initial,start.loc.B,end.loc.B,max.iter)
my_cluster=res_D[[1]]
accuracy=rep(0,factorial(K))
all_perm=permn(seq(1:K))
for (i in 1:factorial(K)){
accuracy[i]=mean(ifelse(abs(match(my_cluster,all_perm[[i]])-cluster_assign),0,1))
}
max(accuracy)
BIC_record[count_K]=-2*res_D[[4]]+log(I*J*3)*(J*2+3*B+4*K-1)
#clear the memory
rm(list=ls(all=TRUE))
source('src.R')
library(maxLik)
#load the coordinates data
map.data=read.csv(file="Coordinates.csv")
# load the methylation data of offspring, mother, and father;
# note that the real data in the paper is not publicly available
# we simulated a data set with K=4 clusters
# the first column is family ID, which is deleted when loading
child=read.csv(file="offspring.csv")[,-1]
mother=read.csv(file="mother.csv")[,-1]
father=read.csv(file="father.csv")[,-1]
set.seed(12345) #set starting seed to make the results the same
# Approach 1: Partition blocks when neighboring CpGs are highly correlated
# First draw scree plot
K_vec=3:6
BIC.value.approach1=GBClust.screeplot(mother=mother,father=father,child=child,K_vec,max.iter=100,block.method='distance',by_dataset='child',map.data=map.data,neighbor.corr.cutoff=0.7)
plot(K_vec,BIC.value.approach1,type='l',xlab='',ylab='',main=paste('BIC scree plot'),lty=1,col=1)
points(K_vec,BIC.value.approach1,pch=1,col=1)
title(ylab="BIC", cex.lab=1.2)
title(xlab="K", cex.lab=1.2)
res.approach1=GBClust(mother=mother,father=father,child=child,K=4,max.iter=100,block.method='distance',by_dataset='child',map.data=map.data,neighbor.corr.cutoff=0.7)
head(res.approach1$cluster.assignment)
res.approach1$Coef
#Approach 2: Partition blocks based on observed correlation through k-means clustering
K_vec=3:6
BIC.value.approach2=GBClust.screeplot(mother=mother,father=father,child=child,K_vec,max.iter=100,block.method='correlation',by_dataset='child',map.data,neighbor.corr.cutoff=0.7,kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
plot(K_vec,BIC.value.approach2,type='l',xlab='',ylab='',main=paste('BIC scree plot'),lty=1,col=1)
points(K_vec,BIC.value.approach2,pch=1,col=1)
title(ylab="BIC", cex.lab=1.2)
title(xlab="K", cex.lab=1.2)
res.approach2=GBClust(mother=mother,father=father,child=child,K=4,max.iter=100,block.method='correlation',by_dataset='child',map.data,neighbor.corr.cutoff=0.7,kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
head(res.approach2$cluster.assignment)
res.approach2$Coef
head(res.approach1$cluster.assignment)
res.approach1$Coef
head(res.approach2$cluster.assignment)
res.approach2$Coef
res.approach2=GBClust(mother=mother,father=father,child=child,K=4,max.iter=100,block.method='correlation',by_dataset='child',kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
BIC.value.approach2=GBClust.screeplot(mother=mother,father=father,child=child,K_vec,max.iter=100,block.method='correlation',by_dataset='child',kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
res.approach2$Coef
head(res.approach2$cluster.assignment)
res.approach2=GBClust(mother=mother,father=father,child=child,K=4,max.iter=100,block.method='correlation',by_dataset='child',kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
K_vec=3:6
BIC.value.approach2=GBClust.screeplot(mother=mother,father=father,child=child,K_vec,max.iter=100,block.method='correlation',by_dataset='child',kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
plot(K_vec,BIC.value.approach2,type='l',xlab='',ylab='',main=paste('BIC scree plot'),lty=1,col=1)
points(K_vec,BIC.value.approach2,pch=1,col=1)
title(ylab="BIC", cex.lab=1.2)
title(xlab="K", cex.lab=1.2)
res.approach2=GBClust(mother=mother,father=father,child=child,K=4,max.iter=100,block.method='correlation',by_dataset='child',kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
head(res.approach2$cluster.assignment)
res.approach2$Coef
plot(K_vec,BIC.value.approach2,type='l',xlab='',ylab='',main=paste('BIC scree plot'),lty=1,col=1)
points(K_vec,BIC.value.approach2,pch=1,col=1)
title(ylab="BIC", cex.lab=1.2)
title(xlab="K", cex.lab=1.2)
#clear the memory
rm(list=ls(all=TRUE))
source('src.R')
library(maxLik)
#load the coordinates data
map.data=read.csv(file="Coordinates.csv")
# load the methylation data of offspring, mother, and father;
# note that the real data in the paper is not publicly available
# we simulated a data set with K=4 clusters
# the first column is family ID, which is deleted when loading
child=read.csv(file="offspring.csv")[,-1]
mother=read.csv(file="mother.csv")[,-1]
father=read.csv(file="father.csv")[,-1]
set.seed(12345) #set starting seed to make the results the same
# Approach 1: Partition blocks when neighboring CpGs are highly correlated
# First draw scree plot
K_vec=3:6
BIC.value.approach1=GBClust.screeplot(mother=mother,father=father,child=child,K_vec,max.iter=100,block.method='distance',by_dataset='child',map.data=map.data,neighbor.corr.cutoff=0.7)
plot(K_vec,BIC.value.approach1,type='l',xlab='',ylab='',main=paste('BIC scree plot'),lty=1,col=1)
points(K_vec,BIC.value.approach1,pch=1,col=1)
title(ylab="BIC", cex.lab=1.2)
title(xlab="K", cex.lab=1.2)
res.approach1=GBClust(mother=mother,father=father,child=child,K=4,max.iter=100,block.method='distance',by_dataset='child',map.data=map.data,neighbor.corr.cutoff=0.7)
head(res.approach1$cluster.assignment)
res.approach1$Coef
#Approach 2: Partition blocks based on observed correlation through k-means clustering
K_vec=3:6
BIC.value.approach2=GBClust.screeplot(mother=mother,father=father,child=child,K_vec,max.iter=100,block.method='correlation',by_dataset='child',kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
plot(K_vec,BIC.value.approach2,type='l',xlab='',ylab='',main=paste('BIC scree plot'),lty=1,col=1)
points(K_vec,BIC.value.approach2,pch=1,col=1)
title(ylab="BIC", cex.lab=1.2)
title(xlab="K", cex.lab=1.2)
res.approach2=GBClust(mother=mother,father=father,child=child,K=4,max.iter=100,block.method='correlation',by_dataset='child',kmean.num=2500,kmean.nstart=50,kmean.iter.max=50,kmean.block.cutoff=0.7)
head(res.approach2$cluster.assignment)
res.approach2$Coef
